## Requirement
* Gemini API Key for gemini version
* Local LLM deployment for ollama version.
    * For a simple ollama deployment on Kubernetes, see [Deployment Ollama on Kubernetes article](https://medium.com/dev-genius/deploying-ollama-on-kubernetes-8a79d0192d24)
    * For a deployment of Kubernetees cluster with GPU, see [GPU Cluster Provisioning](https://medium.com/h7w/gpu-cluster-provisioning-962cc723cc9c)
